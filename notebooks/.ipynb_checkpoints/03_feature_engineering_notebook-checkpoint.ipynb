{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Procurement KPI Analytics - Feature Engineering\n",
    "\n",
    "**Objective**: Create advanced features from cleaned procurement data to enable sophisticated analytics and modeling.\n",
    "\n",
    "**Key Feature Categories**:\n",
    "- Temporal features (seasonality, trends, lead time patterns)\n",
    "- Supplier performance metrics (reliability, risk, efficiency)\n",
    "- Financial engineering (cost optimization, savings patterns)\n",
    "- Quality indicators (defect patterns, improvement trends)\n",
    "- Category-based features (procurement patterns, category performance)\n",
    "- Risk and compliance indicators\n",
    "- Aggregated performance metrics\n",
    "\n",
    "**Input**: Clean procurement dataset from data cleaning phase\n",
    "\n",
    "**Output**: Feature-rich dataset ready for KPI analysis and modeling\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature engineering environment initialized\n",
      "Analysis timestamp: 2025-07-09 07:52:40\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from datetime import datetime, timedelta\n",
    "from typing import Dict, List, Tuple, Any\n",
    "import calendar\n",
    "\n",
    "# Optional imports with fallback\n",
    "try:\n",
    "    from scipy import stats\n",
    "    SCIPY_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"Warning: scipy not available. Some statistical features will be limited.\")\n",
    "    SCIPY_AVAILABLE = False\n",
    "\n",
    "try:\n",
    "    from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "    SKLEARN_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"Warning: scikit-learn not available. Some feature scaling will be limited.\")\n",
    "    SKLEARN_AVAILABLE = False\n",
    "\n",
    "# Configure display\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.float_format', '{:.3f}'.format)\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8')\n",
    "\n",
    "print(\"Feature engineering environment initialized\")\n",
    "print(f\"Analysis timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned dataset loaded successfully\n",
      "Dataset shape: 777 rows x 19 columns\n",
      "\n",
      "Dataset date range: 2022-01-01 00:00:00 to 2024-01-01 00:00:00\n",
      "Data types: {dtype('float64'): 10, dtype('O'): 5, dtype('<M8[ns]'): 2, dtype('int64'): 2}\n"
     ]
    }
   ],
   "source": [
    "# Load cleaned dataset\n",
    "try:\n",
    "    df = pd.read_csv('../data/processed/procurement_data_clean.csv')\n",
    "    print(\"Cleaned dataset loaded successfully\")\n",
    "    print(f\"Dataset shape: {df.shape[0]:,} rows x {df.shape[1]} columns\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: Cleaned dataset not found. Please run the data cleaning notebook first.\")\n",
    "    print(\"Expected file: '../data/processed/procurement_data_clean.csv'\")\n",
    "\n",
    "# Convert date columns if needed\n",
    "date_columns = ['Order_Date', 'Delivery_Date']\n",
    "for col in date_columns:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_datetime(df[col], errors='coerce')\n",
    "\n",
    "print(f\"\\nDataset date range: {df['Order_Date'].min()} to {df['Order_Date'].max()}\")\n",
    "print(f\"Data types: {df.dtypes.value_counts().to_dict()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Temporal Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Temporal Features:\n",
      "========================================\n",
      "Processing Order_Date features...\n",
      "  Created 12 order date features\n",
      "Processing lead time features...\n",
      "  Created 4 lead time features\n",
      "\n",
      "Temporal features created: 15\n"
     ]
    }
   ],
   "source": [
    "# Create comprehensive temporal features\n",
    "def create_temporal_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df_temp = df.copy()\n",
    "    \n",
    "    print(\"Creating Temporal Features:\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Order Date Features\n",
    "    if 'Order_Date' in df_temp.columns:\n",
    "        print(\"Processing Order_Date features...\")\n",
    "        \n",
    "        # Basic date components\n",
    "        df_temp['order_year'] = df_temp['Order_Date'].dt.year\n",
    "        df_temp['order_month'] = df_temp['Order_Date'].dt.month\n",
    "        df_temp['order_quarter'] = df_temp['Order_Date'].dt.quarter\n",
    "        df_temp['order_day_of_week'] = df_temp['Order_Date'].dt.dayofweek\n",
    "        df_temp['order_day_of_month'] = df_temp['Order_Date'].dt.day\n",
    "        df_temp['order_week_of_year'] = df_temp['Order_Date'].dt.isocalendar().week\n",
    "        \n",
    "        # Month and day names for interpretability\n",
    "        df_temp['order_month_name'] = df_temp['Order_Date'].dt.month_name()\n",
    "        df_temp['order_day_name'] = df_temp['Order_Date'].dt.day_name()\n",
    "        \n",
    "        # Seasonal indicators\n",
    "        season_map = {\n",
    "            12: 'Winter', 1: 'Winter', 2: 'Winter',\n",
    "            3: 'Spring', 4: 'Spring', 5: 'Spring',\n",
    "            6: 'Summer', 7: 'Summer', 8: 'Summer',\n",
    "            9: 'Fall', 10: 'Fall', 11: 'Fall'\n",
    "        }\n",
    "        df_temp['order_season'] = df_temp['order_month'].map(season_map)\n",
    "        \n",
    "        # Business vs weekend\n",
    "        df_temp['order_is_weekend'] = df_temp['order_day_of_week'].isin([5, 6])\n",
    "        df_temp['order_is_month_end'] = df_temp['order_day_of_month'] >= 28\n",
    "        df_temp['order_is_quarter_end'] = df_temp['order_month'].isin([3, 6, 9, 12])\n",
    "        \n",
    "        print(f\"  Created 12 order date features\")\n",
    "    \n",
    "    # Lead time features\n",
    "    if 'lead_time_days' in df_temp.columns:\n",
    "        print(\"Processing lead time features...\")\n",
    "        \n",
    "        # Lead time categories\n",
    "        df_temp['lead_time_category'] = pd.cut(df_temp['lead_time_days'], \n",
    "                                              bins=[-np.inf, 7, 14, 30, np.inf],\n",
    "                                              labels=['Express', 'Standard', 'Extended', 'Long'])\n",
    "        \n",
    "        # Lead time efficiency indicators\n",
    "        median_lead_time = df_temp['lead_time_days'].median()\n",
    "        df_temp['lead_time_vs_median'] = df_temp['lead_time_days'] - median_lead_time\n",
    "        df_temp['is_fast_delivery'] = df_temp['lead_time_days'] <= 7\n",
    "        df_temp['is_slow_delivery'] = df_temp['lead_time_days'] >= 30\n",
    "        \n",
    "        print(f\"  Created 4 lead time features\")\n",
    "    \n",
    "    return df_temp\n",
    "\n",
    "# Apply temporal feature engineering\n",
    "df_features = create_temporal_features(df)\n",
    "\n",
    "# Display sample of temporal features\n",
    "temporal_cols = [col for col in df_features.columns if any(x in col for x in ['order_', 'delivery_', 'lead_time_'])]\n",
    "print(f\"\\nTemporal features created: {len(temporal_cols)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Supplier Performance Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Supplier Performance Features:\n",
      "========================================\n",
      "Calculating basic supplier statistics...\n",
      "Creating supplier performance scores...\n",
      "  Created supplier performance features\n",
      "\n",
      "Supplier features created: 15\n"
     ]
    }
   ],
   "source": [
    "# Create supplier performance features\n",
    "def create_supplier_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df_supplier = df.copy()\n",
    "    \n",
    "    print(\"Creating Supplier Performance Features:\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    if 'Supplier' not in df_supplier.columns:\n",
    "        print(\"Warning: Supplier column not found\")\n",
    "        return df_supplier\n",
    "    \n",
    "    # Basic supplier statistics\n",
    "    print(\"Calculating basic supplier statistics...\")\n",
    "    \n",
    "    # Order volume features\n",
    "    supplier_stats = df_supplier.groupby('Supplier').agg({\n",
    "        'PO_ID': 'count',\n",
    "        'Quantity': ['sum', 'mean'],\n",
    "        'total_negotiated_value': ['sum', 'mean'],\n",
    "        'lead_time_days': ['mean', 'std'],\n",
    "        'defect_rate': ['mean', 'std'],\n",
    "        'savings_percentage': ['mean', 'std']\n",
    "    }).round(3)\n",
    "    \n",
    "    # Flatten column names\n",
    "    supplier_stats.columns = ['_'.join(col).strip() if col[1] else col[0] for col in supplier_stats.columns]\n",
    "    \n",
    "    # Rename for clarity\n",
    "    column_mapping = {\n",
    "        'PO_ID_count': 'supplier_total_orders',\n",
    "        'Quantity_sum': 'supplier_total_quantity',\n",
    "        'Quantity_mean': 'supplier_avg_order_quantity',\n",
    "        'total_negotiated_value_sum': 'supplier_total_spend',\n",
    "        'total_negotiated_value_mean': 'supplier_avg_order_value',\n",
    "        'lead_time_days_mean': 'supplier_avg_lead_time',\n",
    "        'lead_time_days_std': 'supplier_lead_time_consistency',\n",
    "        'defect_rate_mean': 'supplier_avg_defect_rate',\n",
    "        'defect_rate_std': 'supplier_quality_consistency',\n",
    "        'savings_percentage_mean': 'supplier_avg_savings_rate',\n",
    "        'savings_percentage_std': 'supplier_savings_consistency'\n",
    "    }\n",
    "    \n",
    "    supplier_stats = supplier_stats.rename(columns=column_mapping)\n",
    "    \n",
    "    # Merge back to main dataframe\n",
    "    df_supplier = df_supplier.merge(supplier_stats, left_on='Supplier', right_index=True, how='left')\n",
    "    \n",
    "    # Create supplier performance scores\n",
    "    print(\"Creating supplier performance scores...\")\n",
    "    \n",
    "    # Delivery performance score (lower lead time is better)\n",
    "    if 'supplier_avg_lead_time' in df_supplier.columns:\n",
    "        lead_time_percentile = df_supplier['supplier_avg_lead_time'].rank(pct=True, ascending=False)\n",
    "        df_supplier['supplier_delivery_score'] = (lead_time_percentile * 100).round(1)\n",
    "    \n",
    "    # Quality performance score (lower defect rate is better)\n",
    "    if 'supplier_avg_defect_rate' in df_supplier.columns:\n",
    "        quality_percentile = df_supplier['supplier_avg_defect_rate'].rank(pct=True, ascending=False)\n",
    "        df_supplier['supplier_quality_score'] = (quality_percentile * 100).round(1)\n",
    "        df_supplier['supplier_quality_score'] = df_supplier['supplier_quality_score'].fillna(100)\n",
    "    \n",
    "    # Overall supplier score (composite)\n",
    "    score_columns = ['supplier_delivery_score', 'supplier_quality_score']\n",
    "    available_scores = [col for col in score_columns if col in df_supplier.columns]\n",
    "    \n",
    "    if available_scores:\n",
    "        df_supplier['supplier_overall_score'] = df_supplier[available_scores].mean(axis=1).round(1)\n",
    "    \n",
    "    # Create supplier tier classification\n",
    "    if 'supplier_overall_score' in df_supplier.columns:\n",
    "        df_supplier['supplier_tier'] = pd.cut(df_supplier['supplier_overall_score'],\n",
    "                                            bins=[0, 60, 80, 90, 100],\n",
    "                                            labels=['Poor', 'Average', 'Good', 'Excellent'])\n",
    "    \n",
    "    print(f\"  Created supplier performance features\")\n",
    "    \n",
    "    return df_supplier\n",
    "\n",
    "# Apply supplier feature engineering\n",
    "df_features = create_supplier_features(df_features)\n",
    "\n",
    "# Display supplier feature summary\n",
    "supplier_cols = [col for col in df_features.columns if 'supplier_' in col]\n",
    "print(f\"\\nSupplier features created: {len(supplier_cols)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Financial Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Financial Features:\n",
      "========================================\n",
      "Creating price analysis features...\n",
      "  Created 3 price analysis features\n",
      "Creating order value features...\n",
      "  Created 2 order value features\n",
      "\n",
      "Financial features created: 4\n"
     ]
    }
   ],
   "source": [
    "# Create financial features\n",
    "def create_financial_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df_financial = df.copy()\n",
    "    \n",
    "    print(\"Creating Financial Features:\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Price analysis features\n",
    "    if all(col in df_financial.columns for col in ['Unit_Price', 'Negotiated_Price']):\n",
    "        print(\"Creating price analysis features...\")\n",
    "        \n",
    "        # Price change metrics\n",
    "        df_financial['price_change_absolute'] = df_financial['Unit_Price'] - df_financial['Negotiated_Price']\n",
    "        df_financial['price_change_ratio'] = df_financial['Negotiated_Price'] / df_financial['Unit_Price']\n",
    "        \n",
    "        # Negotiation effectiveness\n",
    "        df_financial['negotiation_effectiveness'] = np.where(\n",
    "            df_financial['savings_percentage'] > 0, 'Successful',\n",
    "            np.where(df_financial['savings_percentage'] < 0, 'Price_Increase', 'No_Change')\n",
    "        )\n",
    "        \n",
    "        print(f\"  Created 3 price analysis features\")\n",
    "    \n",
    "    # Order value analysis\n",
    "    if 'total_negotiated_value' in df_financial.columns:\n",
    "        print(\"Creating order value features...\")\n",
    "        \n",
    "        # Order size categories\n",
    "        q25 = df_financial['total_negotiated_value'].quantile(0.25)\n",
    "        q75 = df_financial['total_negotiated_value'].quantile(0.75)\n",
    "        \n",
    "        df_financial['order_size_category'] = pd.cut(df_financial['total_negotiated_value'],\n",
    "                                                   bins=[0, q25, q75, np.inf],\n",
    "                                                   labels=['Small', 'Medium', 'Large'])\n",
    "        \n",
    "        # High-value order indicator\n",
    "        value_95th = df_financial['total_negotiated_value'].quantile(0.95)\n",
    "        df_financial['is_high_value_order'] = df_financial['total_negotiated_value'] >= value_95th\n",
    "        \n",
    "        print(f\"  Created 2 order value features\")\n",
    "    \n",
    "    return df_financial\n",
    "\n",
    "# Apply financial feature engineering\n",
    "df_features = create_financial_features(df_features)\n",
    "\n",
    "# Display financial feature summary\n",
    "financial_cols = [col for col in df_features.columns if any(x in col for x in ['price_', 'order_size_', 'negotiation_'])]\n",
    "print(f\"\\nFinancial features created: {len(financial_cols)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Quality Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Quality Features:\n",
      "========================================\n",
      "Creating defect analysis features...\n",
      "  Created 2 defect analysis features\n",
      "Creating compliance features...\n",
      "  Created 1 compliance feature\n",
      "\n",
      "Quality features created: 5\n"
     ]
    }
   ],
   "source": [
    "# Create quality features\n",
    "def create_quality_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df_quality = df.copy()\n",
    "    \n",
    "    print(\"Creating Quality Features:\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Enhanced defect analysis\n",
    "    if all(col in df_quality.columns for col in ['Defective_Units', 'Quantity']):\n",
    "        print(\"Creating defect analysis features...\")\n",
    "        \n",
    "        # Defect severity categories\n",
    "        df_quality['defect_severity'] = pd.cut(df_quality['defect_rate'],\n",
    "                                             bins=[0, 1, 5, 10, 100],\n",
    "                                             labels=['Excellent', 'Good', 'Poor', 'Critical'])\n",
    "        \n",
    "        # Perfect order indicator\n",
    "        df_quality['is_perfect_order'] = (df_quality['Defective_Units'] == 0)\n",
    "        \n",
    "        print(f\"  Created 2 defect analysis features\")\n",
    "    \n",
    "    # Compliance features\n",
    "    if 'Compliance' in df_quality.columns:\n",
    "        print(\"Creating compliance features...\")\n",
    "        \n",
    "        # Compliance scoring\n",
    "        compliance_map = {\n",
    "            'Compliant': 100,\n",
    "            'Non-Compliant': 0,\n",
    "            'Unknown': 50\n",
    "        }\n",
    "        df_quality['compliance_score'] = df_quality['Compliance'].map(compliance_map)\n",
    "        \n",
    "        print(f\"  Created 1 compliance feature\")\n",
    "    \n",
    "    return df_quality\n",
    "\n",
    "# Apply quality feature engineering\n",
    "df_features = create_quality_features(df_features)\n",
    "\n",
    "# Display quality feature summary\n",
    "quality_cols = [col for col in df_features.columns if any(x in col for x in ['defect_', 'compliance_', 'perfect_'])]\n",
    "print(f\"\\nQuality features created: {len(quality_cols)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Risk Assessment Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Risk Assessment Features:\n",
      "========================================\n",
      "Creating performance risk scores...\n",
      "  Created 5 risk scoring features\n",
      "\n",
      "Risk features created: 5\n"
     ]
    }
   ],
   "source": [
    "# Create risk assessment features\n",
    "def create_risk_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df_risk = df.copy()\n",
    "    \n",
    "    print(\"Creating Risk Assessment Features:\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Overall performance risk score\n",
    "    print(\"Creating performance risk scores...\")\n",
    "    \n",
    "    # Initialize risk components\n",
    "    risk_components = {}\n",
    "    \n",
    "    # Delivery risk\n",
    "    if 'lead_time_days' in df_risk.columns:\n",
    "        lead_time_95th = df_risk['lead_time_days'].quantile(0.95)\n",
    "        risk_components['delivery_risk'] = (df_risk['lead_time_days'] > lead_time_95th).astype(int)\n",
    "    \n",
    "    # Quality risk\n",
    "    if 'defect_rate' in df_risk.columns:\n",
    "        risk_components['quality_risk'] = (df_risk['defect_rate'] > 5).astype(int)\n",
    "    \n",
    "    # Compliance risk\n",
    "    if 'Compliance' in df_risk.columns:\n",
    "        risk_components['compliance_risk'] = (df_risk['Compliance'] == 'Non-Compliant').astype(int)\n",
    "    \n",
    "    # Add risk components to dataframe\n",
    "    for risk_name, risk_values in risk_components.items():\n",
    "        df_risk[risk_name] = risk_values\n",
    "    \n",
    "    # Calculate composite risk score\n",
    "    if risk_components:\n",
    "        df_risk['composite_risk_score'] = sum(risk_components.values())\n",
    "        df_risk['risk_level'] = pd.cut(df_risk['composite_risk_score'],\n",
    "                                     bins=[-1, 0, 1, 2, len(risk_components)],\n",
    "                                     labels=['Low', 'Medium', 'High', 'Critical'])\n",
    "    \n",
    "    print(f\"  Created {len(risk_components) + 2} risk scoring features\")\n",
    "    \n",
    "    return df_risk\n",
    "\n",
    "# Apply risk feature engineering\n",
    "df_features = create_risk_features(df_features)\n",
    "\n",
    "# Display risk feature summary\n",
    "risk_cols = [col for col in df_features.columns if any(x in col for x in ['risk_', 'risk'])]\n",
    "print(f\"\\nRisk features created: {len(risk_cols)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Feature Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Engineering Summary:\n",
      "==================================================\n",
      "Original features: 19\n",
      "Total features after engineering: 63\n",
      "New features created: 44\n",
      "Feature expansion ratio: 3.32x\n",
      "\n",
      "Features by Category:\n",
      "  Original Features: 19 features\n",
      "  Temporal Features: 21 features\n",
      "  Supplier Features: 15 features\n",
      "  Financial Features: 4 features\n",
      "  Quality Features: 6 features\n",
      "  Risk Features: 5 features\n"
     ]
    }
   ],
   "source": [
    "# Comprehensive feature summary\n",
    "print(\"Feature Engineering Summary:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Count features by category\n",
    "feature_categories = {\n",
    "    'Original Features': [col for col in df.columns],\n",
    "    'Temporal Features': [col for col in df_features.columns if any(x in col for x in ['order_', 'delivery_', 'lead_time_'])],\n",
    "    'Supplier Features': [col for col in df_features.columns if 'supplier_' in col],\n",
    "    'Financial Features': [col for col in df_features.columns if any(x in col for x in ['price_', 'order_size_', 'negotiation_'])],\n",
    "    'Quality Features': [col for col in df_features.columns if any(x in col for x in ['defect_', 'compliance_', 'perfect_'])],\n",
    "    'Risk Features': [col for col in df_features.columns if any(x in col for x in ['risk_', 'risk'])]\n",
    "}\n",
    "\n",
    "total_original = len(feature_categories['Original Features'])\n",
    "total_current = len(df_features.columns)\n",
    "total_new = total_current - total_original\n",
    "\n",
    "print(f\"Original features: {total_original}\")\n",
    "print(f\"Total features after engineering: {total_current}\")\n",
    "print(f\"New features created: {total_new}\")\n",
    "print(f\"Feature expansion ratio: {total_current/total_original:.2f}x\")\n",
    "\n",
    "print(\"\\nFeatures by Category:\")\n",
    "for category, features in feature_categories.items():\n",
    "    print(f\"  {category}: {len(features)} features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Export Engineered Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting Feature Dataset:\n",
      "==================================================\n",
      "Feature dataset exported to: ../data/processed/procurement_features_engineered.csv\n",
      "Records: 777 | Features: 63\n",
      "Feature metadata exported to: ../data/processed/feature_metadata.csv\n",
      "Feature summary exported to: ../data/processed/feature_engineering_summary.txt\n",
      "\n",
      "Feature Engineering Complete!\n",
      "Dataset enhanced from 19 to 63 features\n",
      "Ready for KPI analysis and modeling\n"
     ]
    }
   ],
   "source": [
    "# Export engineered dataset\n",
    "import os\n",
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs('../data/processed', exist_ok=True)\n",
    "\n",
    "print(\"Exporting Feature Dataset:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Export main feature dataset\n",
    "output_path = '../data/processed/procurement_features_engineered.csv'\n",
    "df_features.to_csv(output_path, index=False)\n",
    "print(f\"Feature dataset exported to: {output_path}\")\n",
    "print(f\"Records: {len(df_features):,} | Features: {len(df_features.columns)}\")\n",
    "\n",
    "# Create and export feature metadata\n",
    "feature_metadata = pd.DataFrame({\n",
    "    'Feature_Name': df_features.columns,\n",
    "    'Data_Type': df_features.dtypes,\n",
    "    'Non_Null_Count': df_features.count(),\n",
    "    'Null_Count': df_features.isnull().sum(),\n",
    "    'Null_Percentage': (df_features.isnull().sum() / len(df_features) * 100).round(2)\n",
    "})\n",
    "\n",
    "metadata_path = '../data/processed/feature_metadata.csv'\n",
    "feature_metadata.to_csv(metadata_path, index=False)\n",
    "print(f\"Feature metadata exported to: {metadata_path}\")\n",
    "\n",
    "# Export feature summary\n",
    "summary_path = '../data/processed/feature_engineering_summary.txt'\n",
    "with open(summary_path, 'w') as f:\n",
    "    f.write(\"PROCUREMENT FEATURE ENGINEERING SUMMARY\\n\")\n",
    "    f.write(\"=\" * 50 + \"\\n\")\n",
    "    f.write(f\"Engineering Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "    f.write(f\"Original Features: {total_original}\\n\")\n",
    "    f.write(f\"Engineered Features: {total_current}\\n\")\n",
    "    f.write(f\"New Features Created: {total_new}\\n\")\n",
    "    f.write(f\"Feature Expansion Ratio: {total_current/total_original:.2f}x\\n\")\n",
    "    \n",
    "    f.write(\"\\nFEATURE CATEGORIES:\\n\")\n",
    "    for category, features in feature_categories.items():\n",
    "        f.write(f\"  {category}: {len(features)} features\\n\")\n",
    "\n",
    "print(f\"Feature summary exported to: {summary_path}\")\n",
    "\n",
    "print(f\"\\nFeature Engineering Complete!\")\n",
    "print(f\"Dataset enhanced from {total_original} to {total_current} features\")\n",
    "print(f\"Ready for KPI analysis and modeling\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Feature Engineering Complete!\n",
    "\n",
    "**Major Accomplishments:**\n",
    "- Created comprehensive temporal features for seasonality and trend analysis\n",
    "- Developed supplier performance scoring and assessment metrics\n",
    "- Engineered financial and cost optimization features\n",
    "- Built quality and compliance monitoring indicators\n",
    "- Implemented risk assessment scoring systems\n",
    "\n",
    "**Key Feature Categories Created:**\n",
    "- **Temporal Features**: Seasonality, business cycles, lead time patterns\n",
    "- **Supplier Features**: Performance scores, tier classifications\n",
    "- **Financial Features**: Price analysis, order categorization, negotiation effectiveness\n",
    "- **Quality Features**: Defect severity, compliance scoring, perfect order tracking\n",
    "- **Risk Features**: Composite risk scoring, performance risk assessment\n",
    "\n",
    "**Ready for Next Phase:**\n",
    "- **KPI Analysis** (Notebook 04) - Calculate and visualize key performance indicators\n",
    "- **Supplier Performance Analysis** (Notebook 05) - Deep dive into supplier metrics\n",
    "- **Predictive Modeling** (Notebook 06) - Build forecasting and prediction models\n",
    "\n",
    "**Files Generated:**\n",
    "- `procurement_features_engineered.csv` - Enhanced dataset with engineered features\n",
    "- `feature_metadata.csv` - Complete feature documentation\n",
    "- `feature_engineering_summary.txt` - Summary and documentation\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
